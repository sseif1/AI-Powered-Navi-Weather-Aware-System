# AI-Powered-Navi-Weather-Aware-System

Domain Adaptive Object Detection for Autonomous Driving under Adverse Weather Conditions
This project introduces a weather-aware voice-interactive assistant designed to enhance object detection under adverse weather conditions using domain-adaptive computer vision techniques. Adverse weather significantly reduces the visibility and reliability of RGB-based detection systems, leading to missed or incorrect detections in autonomous navigation systems. Our pipeline incorporates synthetic weather augmentation (fog, rain, snow), image preprocessing (CLAHE and gamma correction), and a dual-branch architecture featuring a YOLOv8 detector and a ResNet-based weather classifier. The detection output is converted into natural language alerts using a voice synthesis engine to guide users or autonomous systems in real time. Evaluated across real and synthetic datasets (BDD100K, Foggy Cityscapes), our solution demonstrates improved object detection performance under foggy conditions, confirming the effectiveness of adversarial domain adaptation. The solution is scalable, modular, and effective for human-interactive autonomous systems in low-visibility environments.
